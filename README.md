# ğŸ¦ LedgerMind: Financial RAG vs. Fine-Tuning Benchmark

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

> **High-Stakes Financial RAG Framework**  
> A production-grade framework evaluating the trade-offs between **Parametric Memory (Fine-Tuning)** and **Non-Parametric Memory (Advanced RAG)** for high-stakes financial data interpretation.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Engineering Insights](#engineering-insights)
- [Key Findings](#key-findings)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Technical Architecture](#technical-architecture)
- [Configuration](#configuration)
- [Dependencies](#dependencies)
- [Troubleshooting](#troubleshooting)
- [License](#license)

---

## ğŸ¯ Overview

**LedgerMind** is an experimental AI architecture designed to solve the "Hallucination vs. Reasoning" dilemma in financial analysis. This project implements and rigorously evaluates two competing architectures for processing 100+ page Annual Reports:

1. **Architecture A ("The Intern"):** A Fine-tuned Llama-3-8B model that prioritizes domain-specific syntax and style (Parametric Memory).
2. **Architecture B ("The Librarian"):** An Advanced RAG system utilizing Hybrid Search (Dense + BM25) and Reciprocal Rank Fusion (Non-Parametric Memory).

### The Engineering Challenge

Financial data requires zero tolerance for hallucination. This project builds a **synthetic evaluation pipeline** (using Gemma 3 and DeepSeek-R1) to conduct a head-to-head showdown on 1,600+ Q&A pairs from Uber's 2024 Annual Report, measuring:

* **Factuality:** Can it cite specific legal codes? (RAG domain)
* **Reasoning:** Can it synthesize trends across chapters? (Fine-Tuning domain)
* **Cost/Latency:** Which architecture scales better in production?

---

## ğŸ’¡ Engineering Insights

Building this framework revealed a critical production constraint: **Hybrid Routing is Mandatory.**

* **The "Vibe" Trap:** The Fine-Tuned model scored **4.01/5** on judge scores because it sounded confident and professional.
* **The "Fact" Reality:** Despite high judge scores, the Fine-Tuned model had a **24.8% error rate** on specific numbers (e.g., page references).

### Production Strategy

Based on this data, a production deployment should not choose *one* model. It should use a **Router**:

1. **Route "Summarize strategic risks"** â†’ Fine-Tuned Model (Better synthesis/reasoning).
2. **Route "What was the EBITDA in Q3?"** â†’ RAG System (Better precision/retrieval).

---

## ğŸ† Key Findings

| Metric | RAG + RRF | Fine-Tuned | Winner |
|--------|-----------|------------|---------|
| **Judge Score** (1-5) | 2.54 | **4.01** | ğŸ¥‡ Fine-Tuned |
| **ROUGE-L** (0-1) | 0.121 | **0.608** | ğŸ¥‡ Fine-Tuned |
| **Latency** (ms) | **1,696** | 2,524 | ğŸ¥‡ RAG |
| **Head-to-Head Wins** | 49 | **346** | ğŸ¥‡ Fine-Tuned |
| **Win Margin** | - | **61.1%** | ğŸ¥‡ Fine-Tuned |
| **Monthly Cost** | $454 | **$409** | ğŸ¥‡ Fine-Tuned |

### ğŸ“Š Verdict

**The Fine-Tuned Model wins overall** with superior accuracy and coherence. However, it exhibits significant failures on precision-critical queries, including:

- âŒ Citation confabulation (inventing legal codes)
- âŒ Page number omissions
- âŒ Parametric mixing (blending unrelated sections)

---

## ğŸ“ Project Structure

```
./
â”œâ”€â”€ .env                          # Environment variables (API keys)
â”œâ”€â”€ .gitignore                    # Git ignore patterns
â”œâ”€â”€ .python-version               # Python version specification
â”œâ”€â”€ pyproject.toml                # UV/pip dependency management
â”œâ”€â”€ uv.lock                       # Locked dependencies
â”œâ”€â”€ README.md                     # This file
â”‚
â”œâ”€â”€ artifacts/                    # Generated outputs & results
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ train.jsonl           # 1,146 training Q&A pairs
â”‚   â”‚   â”œâ”€â”€ golden_test_set.jsonl # 487 test Q&A pairs
â”‚   â”‚   â””â”€â”€ intern_predictions.jsonl # Fine-tuned model predictions
â”‚   â””â”€â”€ outputs/
â”‚       â”œâ”€â”€ final_showdown.csv    # Comprehensive evaluation results
â”‚       â””â”€â”€ llama-3-financial-intern.zip # LoRA adapter weights
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdfs/
â”‚       â””â”€â”€ 2024-Annual-Report.pdf # Source document (Uber)
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter workflows (execute in order)
â”‚   â”œâ”€â”€ 01_data_factory.ipynb     # Synthetic dataset generation
â”‚   â”œâ”€â”€ 02_finetuning_intern.ipynb # LoRA fine-tuning pipeline
â”‚   â”œâ”€â”€ 03_rag_librarian.ipynb    # Hybrid RAG + RRF system
â”‚   â””â”€â”€ 04_evaluation_arena.ipynb # Head-to-head evaluation
â”‚
â”œâ”€â”€ src/                          # Core application code
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.yaml           # System configuration
â”‚   â”‚   â””â”€â”€ prompts.yaml          # Prompt templates
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ data_manager.py       # Data loading utilities
â”‚       â””â”€â”€ llm_services.py       # LLM API wrappers
â”‚
â””â”€â”€ utils/                        # Utility scripts
    â”œâ”€â”€ hallucination_finder.py   # Error analysis tools
    â””â”€â”€ submission_checker.py     # Validation scripts
```

---

## ğŸš€ Installation

### Prerequisites

- **Python 3.11+**
- **CUDA-capable GPU** (for fine-tuning) or **Google Colab T4** (free tier)
- **[UV package manager](https://github.com/astral-sh/uv)** (recommended) or pip

### Step 1: Clone the Repository

```bash
git clone https://github.com/yourusername/ledger-mind.git
cd ledger-mind
```

### Step 2: Install Dependencies

**Option A: Using UV (Recommended)**

```bash
# Install UV if not already installed
curl -LsSf https://astral.sh/uv/install.sh | sh

# Sync dependencies
uv sync
```

**Option B: Using pip**

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt  # Note: Generate from pyproject.toml if needed
```

### Step 3: Set Up Environment Variables

Create a `.env` file in the project root:

```bash
# LLM API Keys
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
GOOGLE_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Weaviate Cloud (for RAG system)
WEAVIATE_URL=https://xxxxxxxx.weaviate.network
WEAVIATE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

---

## ğŸ’» Usage

### 1ï¸âƒ£ Data Generation (Synthetic Pipeline)

Generate synthetic Q&A pairs from the annual report using Gemma 3:

```bash
jupyter notebook notebooks/01_data_factory.ipynb
```

**Key Features:**
- Teacher-student architecture (Gemma 3:4B â†’ Llama-3.3-70B)
- Structured prompting (40% hard facts, 30% strategic, 30% stylistic)

### 2ï¸âƒ£ Fine-Tuning "The Intern"

Train the parametric memory model using Unsloth and LoRA:

```bash
jupyter notebook notebooks/02_finetuning_intern.ipynb
```

**Configuration:**
- Base model: `unsloth/llama-3-8b-Instruct-bnb-4bit`
- LoRA (r=16, alpha=16) on attention layers
- 120 training steps, 4-bit NF4 quantization

### 3ï¸âƒ£ Building "The Librarian" (RAG)

Deploy the advanced hybrid retrieval system:

```bash
jupyter notebook notebooks/03_rag_librarian.ipynb
```

**Pipeline:**
1. Dense Vector Search (top-20) â†’ `all-MiniLM-L6-v2`
2. BM25 Keyword Search (top-20) â†’ Exact entity matching
3. Reciprocal Rank Fusion (k=60) â†’ Combine rankings
4. Cross-Encoder Reranking (top-10) â†’ `ms-marco-MiniLM-L-6-v2`

### 4ï¸âƒ£ Evaluation Arena

Run the head-to-head showdown using LLM-as-a-Judge (DeepSeek-R1):

```bash
jupyter notebook notebooks/04_evaluation_arena.ipynb
```

---

## ğŸ—ï¸ Technical Architecture

### The Intern (Fine-Tuning)

```python
# LoRA Configuration
lora_config = LoraConfig(
    r=16,                    # Low-rank dimension
    lora_alpha=16,           # Scaling factor
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_dropout=0.0,
    bias="none"
)
```

### The Librarian (RAG + RRF)

```python
def reciprocal_rank_fusion(ranked_lists, k=60):
    """
    RRF(d) = Î£ [1 / (k + rank_i(d))]
    Combines dense vector search + BM25 keyword search
    """
    rrf_scores = {}
    for ranked_list in ranked_lists:
        for rank, (doc_id, doc_obj) in enumerate(ranked_list):
            if doc_id not in rrf_scores:
                rrf_scores[doc_id] = {'score': 0.0, 'doc': doc_obj}
            rrf_scores[doc_id]['score'] += 1.0 / (k + rank + 1)
    return rrf_scores
```

---

## âš™ï¸ Configuration

### LLM Providers (`src/config/config.yaml`)

```yaml
providers:
  ollama:
    model: "gemma3:4b"
    judge_model: "llama3.2:latest"
  
  openrouter:
    llm_a_model: "google/gemini-2.0-flash-001"
    llm_b_model: "meta-llama/llama-3.3-70b-instruct"
    judge_model: "deepseek/deepseek-r1:free"
```

### RAG Configuration

```yaml
weaviate:
  vectorizer_model: "sentence-transformers/all-MiniLM-L6-v2"
  reranker_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"

retrieval:
  dense_top_k: 20      # Vector search candidates
  bm25_top_k: 20       # Keyword search candidates
  rrf_k: 60            # RRF constant
  final_top_k: 10      # After reranking
```

---

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. CUDA Out of Memory (OOM)

**Solutions:**
- Reduce batch size to 1.
- Enable `gradient_checkpointing = True`.
- If using Colab, ensure you are on T4 High-RAM runtime.

#### 2. OpenRouter API Rate Limits

**Solutions:**
- Implement exponential backoff (script provided in `utils/`).
- The pipeline defaults to a 1-second delay between calls.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

<div align="center">

**Built by Builders, for Builders.**

[Report Bug](https://github.com/yourusername/ledger-mind/issues) Â· [Request Feature](https://github.com/yourusername/ledger-mind/issues)

</div>
